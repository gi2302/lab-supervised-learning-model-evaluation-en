{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCRIM - per capita crime rate by town\\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\\nINDUS - proportion of non-retail business acres per town.\\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\\nNOX - nitric oxides concentration (parts per 10 million)\\nRM - average number of rooms per dwelling\\nAGE - proportion of owner-occupied units built prior to 1940\\nDIS - weighted distances to five Boston employment centres\\nRAD - index of accessibility to radial highways\\nTAX - full-value property-tax rate per $10,000\\nPTRATIO - pupil-teacher ratio by town\\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\nLSTAT - % lower status of the population\\nMEDV - Median value of owner-occupied homes in $1000's\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CRIM - per capita crime rate by town\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - % lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (X_train): (404, 13)\n",
      "Testing Features (X_test): (102, 13)\n",
      "Training Target (y_train): (404,)\n",
      "Testing Target (y_test): (102,)\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the feature columns (all columns except 'MEDV')\n",
    "X = data.drop('MEDV', axis=1)\n",
    "\n",
    "# Define the target variable ('MEDV')\n",
    "y = data['MEDV']\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets with labels\n",
    "print(f\"Training Features (X_train): {X_train.shape}\")\n",
    "print(f\"Testing Features (X_test): {X_test.shape}\")\n",
    "print(f\"Training Target (y_train): {y_train.shape}\")\n",
    "print(f\"Testing Target (y_test): {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "\n",
    "The dataset has been successfully split into training and testing sets, with the following shapes:\n",
    "\n",
    "- **Training Features (X_train)**: `(404, 13)`  \n",
    "  This represents 404 rows of training data with 13 feature columns (i.e., all the variables except `MEDV`).\n",
    "\n",
    "- **Testing Features (X_test)**: `(102, 13)`  \n",
    "  This represents 102 rows of testing data with 13 feature columns.\n",
    "\n",
    "- **Training Target (y_train)**: `(404,)`  \n",
    "  This represents the target variable `MEDV` for the training set, consisting of 404 values.\n",
    "\n",
    "- **Testing Target (y_test)**: `(102,)`  \n",
    "  This represents the target variable `MEDV` for the testing set, consisting of 102 values.\n",
    "\n",
    "The data is split in a way that 80% of the dataset is used for training and 20% is used for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Predictions: [10.96952405 19.41196567 23.06419602 12.1470648  18.3738116  25.24677946\n",
      " 20.77024774 23.90932632  7.81713319 19.60988098 21.8202963  27.59615864\n",
      " 32.67986504 15.12308446 35.3964561  12.99688651 20.728181   28.30223542\n",
      " 15.61724836 24.45143096  4.61794591 23.76681932 25.56178249 22.98928526\n",
      " 24.5213025  34.06407919 19.71166707 39.11233072 14.62515846 24.81139885\n",
      " 18.02332883 20.85836445  9.57577261 20.87246835 22.28583096 31.79327155\n",
      " 31.04748307 15.70611763 17.01382935 28.23332703 24.27661276 16.88670215\n",
      "  6.90720745 26.75808901 22.586493   17.53664716 13.77197016 41.04840929\n",
      " 16.44690754 18.23531669 25.37038646 23.64581399 22.05322581 20.83620499\n",
      " 16.93508273 22.797579   29.13333934  7.69310515 24.60571452 17.2358028\n",
      " 21.10846551 25.15150324 27.33394823 21.30494963 41.5811902  19.19666651\n",
      " 15.37955448 19.33545877 17.04687638 22.96801532 23.11094953 33.6977586\n",
      " 22.77436405 20.28968381 25.35517813 31.02479125 33.05103792 28.44712333\n",
      "  8.50926331  5.61220643 12.81228164 19.81854491 34.8603548  33.47481463\n",
      " 15.81288676  4.16863764 32.81131556 21.22307142 18.97752706 26.36174269\n",
      " 18.38053781 17.80316891 11.8730344  31.84801205 24.45344478 20.0222241\n",
      " 19.5225374  11.8723419  28.90289906 19.7133604  32.47093634 33.20696505\n",
      " 24.79405395 21.25197228 25.03045081 43.36995367 29.54151469 33.75302939\n",
      " 26.27516427 27.04791799 15.1908027  31.34177077 20.85218327 31.05070715\n",
      " 28.74449991 21.16535503 23.06717742 12.48881717 36.48751917 37.24291141\n",
      " 33.23617345  5.30863493 20.82773333 22.16769067 35.62579793 17.10890633\n",
      " 22.76667    19.50567599 26.36980524 16.03780391 20.63186041 27.04508116\n",
      " 31.39596353 31.12597743 22.78355908 39.11521781 28.28378993 30.53090392\n",
      " 28.89518723 21.08389783 29.04801464 16.151087   22.08243372 24.61505524\n",
      " 18.95878457  2.06366066 20.51120467 26.85927261 23.0775764  18.40141847\n",
      " 22.70378324 15.95162657 31.54559763 27.82356386 34.19210038 20.70876151\n",
      " 15.1538496  19.55740929  8.31853813 13.62525632 26.48611752 16.52769982\n",
      "  4.13593772 24.73356662 12.21856959 28.24704463 33.60549853 36.84177072\n",
      " 24.28136146 20.7199677  30.79885576 36.93823489 19.92152434 19.59433404\n",
      " 28.76197718 13.28347615 13.41116334 10.89910148 19.07573086 22.65911351\n",
      " 30.27080271 29.77482371 17.89252221 29.83838757 14.41987694 13.24056207\n",
      " 33.87859379 19.6406762  14.54072369 23.66498192 22.41851151 19.63248447\n",
      " 24.660086   35.00833944  4.12171868 20.79593953 33.240402   18.04778742\n",
      " 22.6208596  22.39592759 21.4012853  11.74782838 38.18786922 25.76751814\n",
      " 24.80115706 16.36524419 31.98045427 36.35420843 39.11016375 20.33864814\n",
      " 22.16464728 16.34276966 39.35137104  6.74954317 21.35789894 15.53370378\n",
      " 26.91527204  8.80382559 20.93301971 -0.20588155 17.21501492 16.17150935\n",
      "  8.48374754 23.08202496 17.23085262 29.42673011 44.36436789 28.09470335\n",
      " 23.75911874 36.75959172  8.71594791 25.90885934 20.83832124 23.68119542\n",
      " 19.85753143 22.2992237  14.72942336 18.4266911  22.45346464 23.75648384\n",
      " 28.82492146 23.58310886 27.30142666 18.06532614 13.16799771 31.66795775\n",
      " 28.77291955 12.60179253 17.38668341 24.05174693 40.7163898  23.0214736\n",
      " 12.83596226 28.55024128 36.850343   23.26391794 25.14113573 38.36624745\n",
      " 18.21318365 25.69614391 15.22833068 24.14345412 36.27095489 31.03140871\n",
      " 24.82017075 17.7834844  17.99307546  8.61827851 41.51965821 19.63259696\n",
      " 30.16241039 19.69581658 14.59963591 20.29467675 24.22053288 34.79282666\n",
      " 26.51552807 41.665796   12.32829593 14.32092274 23.69090327 18.01762114\n",
      " 19.72399411 29.13009315 11.10216617 24.11213143 18.54668994 23.69765843\n",
      " 30.11853879 19.34756033 12.52355093 33.74737806 16.90295464 17.83165159\n",
      " 19.34064029 26.74379491 35.24575625 12.92253178 26.69073573 19.19640769\n",
      " 30.29549933 17.83878909 22.92058129 29.13254708 20.02093559 25.18893157\n",
      " 20.95650827 20.57624549 32.93168351 20.43565472 25.41798459 28.14952635\n",
      " 37.59066882 25.0548289  28.61534646 17.97695227 30.78085325 23.57491321\n",
      " 34.56676284 18.52592551 23.86972656 13.82862001 25.18152388 17.67219765\n",
      " 12.63704156 17.03927502 14.2510159  28.56862619 22.99037971 13.42262376\n",
      " 17.40965124 34.44268371 12.93938984 14.62427657 27.50209814 21.28772373\n",
      " 21.8475453  27.75030943 16.84106111 35.70395065 23.19717187 19.70894368\n",
      " 20.39856551 31.03155183  5.16165827 36.26386827 38.27409562 21.44507004\n",
      " 21.53203698 13.25546637 35.43733953 19.75468373 21.59325014 27.28654912\n",
      " 14.70336355 20.10948908 20.98738625 20.42268561 26.20840113 11.28815662\n",
      " 34.57059129 22.65270668 22.68814063 33.20155069 26.77878535 21.55230365\n",
      "  8.80963918 28.40878163 25.10012639 25.47646583 17.70215249 25.63601841\n",
      " 18.61140436 32.77937269 35.77461311 18.3180684  30.14080347  7.72488159\n",
      " 26.25987699 10.52826879 27.30604251 44.10078731 28.92351314 14.7836951\n",
      " 20.79445301 17.96782515 19.333174   33.02714571 25.71055958 25.89232968\n",
      " 17.07165041 21.95432205 11.3511532  13.27742402 22.66485295 22.52252947\n",
      " 12.30424735 32.08396429 22.11175771 17.24071878 22.00480027 26.7237425\n",
      " 12.97674212 19.14279551]\n",
      "Testing Set Predictions: [28.99672362 36.02556534 14.81694405 25.03197915 18.76987992 23.25442929\n",
      " 17.66253818 14.34119    23.01320703 20.63245597 24.90850512 18.63883645\n",
      " -6.08842184 21.75834668 19.23922576 26.19319733 20.64773313  5.79472718\n",
      " 40.50033966 17.61289074 27.24909479 30.06625441 11.34179277 24.16077616\n",
      " 17.86058499 15.83609765 22.78148106 14.57704449 22.43626052 19.19631835\n",
      " 22.43383455 25.21979081 25.93909562 17.70162434 16.76911711 16.95125411\n",
      " 31.23340153 20.13246729 23.76579011 24.6322925  13.94204955 32.25576301\n",
      " 42.67251161 17.32745046 27.27618614 16.99310991 14.07009109 25.90341861\n",
      " 20.29485982 29.95339638 21.28860173 34.34451856 16.04739105 26.22562412\n",
      " 39.53939798 22.57950697 18.84531367 32.72531661 25.0673037  12.88628956\n",
      " 22.68221908 30.48287757 31.52626806 15.90148607 20.22094826 16.71089812\n",
      " 20.52384893 25.96356264 30.61607978 11.59783023 20.51232627 27.48111878\n",
      " 11.01962332 15.68096344 23.79316251  6.19929359 21.6039073  41.41377225\n",
      " 18.76548695  8.87931901 20.83076916 13.25620627 20.73963699  9.36482222\n",
      " 23.22444271 31.9155003  19.10228271 25.51579303 29.04256769 20.14358566\n",
      " 25.5859787   5.70159447 20.09474756 14.95069156 12.50395648 20.72635294\n",
      " 24.73957161 -0.164237   13.68486682 16.18359697 22.27621999 24.47902364]\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on both the training and testing sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Display the predictions for both sets\n",
    "print(f\"Training Set Predictions: {y_train_pred}\")\n",
    "print(f\"Testing Set Predictions: {y_test_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Training and Testing Sets\n",
    "\n",
    "The model has been successfully trained, and predictions have been generated for both the training and testing sets. Below are the results:\n",
    "\n",
    "- **Training Set Predictions**: These are the predicted values for the `MEDV` target variable based on the training data. There are 404 predictions, corresponding to the 404 samples in the training set. These predictions represent the estimated median values of owner-occupied homes in $1000's.\n",
    "\n",
    "- **Testing Set Predictions**: These are the predicted values for the `MEDV` target variable based on the testing data. There are 102 predictions, corresponding to the 102 samples in the testing set. These predictions represent the estimated median values of owner-occupied homes in $1000's for the testing set.\n",
    "\n",
    "The model's performance will be evaluated using various metrics such as Mean Squared Error (MSE) and R-squared in the subsequent steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for Training Set: 0.7508856358979673\n",
      "R-squared for Testing Set: 0.6687594935356307\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared for both training and testing sets\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the R-squared values\n",
    "print(f\"R-squared for Training Set: {r2_train}\")\n",
    "print(f\"R-squared for Testing Set: {r2_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared Values for Training and Testing Sets\n",
    "\n",
    "The R-squared values for both the training and testing sets have been calculated:\n",
    "\n",
    "- **R-squared for Training Set**: This value indicates how well the model fits the training data. An R-squared value of 0.7509 means that approximately 75.09% of the variance in the training data is explained by the model.\n",
    "\n",
    "- **R-squared for Testing Set**: This value indicates how well the model generalizes to the testing data. An R-squared value of 0.6688 means that approximately 66.88% of the variance in the testing data is explained by the model.\n",
    "\n",
    "The R-squared values suggest that the model performs well, but there is room for improvement, especially in generalizing to the testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Training Set: 21.641412753226312\n",
      "Mean Squared Error for Testing Set: 24.291119474973613\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate Mean Squared Error for both training and testing sets\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the Mean Squared Error values\n",
    "print(f\"Mean Squared Error for Training Set: {mse_train}\")\n",
    "print(f\"Mean Squared Error for Testing Set: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error for Training and Testing Sets\n",
    "\n",
    "The Mean Squared Error (MSE) values for both the training and testing sets have been calculated:\n",
    "\n",
    "- **Mean Squared Error for Training Set**: The MSE for the training set is 21.64. This value indicates the average squared difference between the predicted and actual values for the training data. A lower MSE indicates a better fit to the training data.\n",
    "\n",
    "- **Mean Squared Error for Testing Set**: The MSE for the testing set is 24.29. This value represents the average squared difference between the predicted and actual values for the testing data. The MSE for the testing set is slightly higher than that of the training set, which suggests that the model might be overfitting to the training data.\n",
    "\n",
    "Overall, the MSE values provide insight into the model's accuracy, with a lower MSE indicating better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Training Set: 3.314771626783227\n",
      "Mean Absolute Error for Testing Set: 3.189091965887852\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate Mean Absolute Error for both training and testing sets\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the Mean Absolute Error values\n",
    "print(f\"Mean Absolute Error for Training Set: {mae_train}\")\n",
    "print(f\"Mean Absolute Error for Testing Set: {mae_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error for Training and Testing Sets\n",
    "\n",
    "The Mean Absolute Error (MAE) values for both the training and testing sets have been calculated:\n",
    "\n",
    "- **Mean Absolute Error for Training Set**: The MAE for the training set is 3.31. This value indicates the average absolute difference between the predicted and actual values for the training data. A lower MAE indicates a better fit to the training data.\n",
    "\n",
    "- **Mean Absolute Error for Testing Set**: The MAE for the testing set is 3.19. This value represents the average absolute difference between the predicted and actual values for the testing data. The MAE for the testing set is slightly lower than that of the training set, suggesting that the model is performing well on the testing data.\n",
    "\n",
    "The MAE values show that the model is making predictions with an average error of about 3.19 to 3.31 units for both the training and testing sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - sepal length in cm\n",
      "    - sepal width in cm\n",
      "    - petal length in cm\n",
      "    - petal width in cm\n",
      "    - class:\n",
      "            - Iris-Setosa\n",
      "            - Iris-Versicolour\n",
      "            - Iris-Virginica\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============== ==== ==== ======= ===== ====================\n",
      "                Min  Max   Mean    SD   Class Correlation\n",
      "============== ==== ==== ======= ===== ====================\n",
      "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "============== ==== ==== ======= ===== ====================\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: 33.3% for each of 3 classes.\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "    Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "    Structure and Classification Rule for Recognition in Partially Exposed\n",
      "    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "    on Information Theory, May 1972, 431-433.\n",
      "  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "    conceptual clustering system finds 3 classes in the data.\n",
      "  - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset Description\n",
    "\n",
    "The Iris dataset is one of the most well-known datasets in the field of pattern recognition and is often used for classification tasks. The dataset consists of 150 instances, with 50 instances in each of three classes: Iris-Setosa, Iris-Versicolour, and Iris-Virginica. Each instance is described by four numeric attributes:\n",
    "\n",
    "- **Sepal Length (cm)**\n",
    "- **Sepal Width (cm)**\n",
    "- **Petal Length (cm)**\n",
    "- **Petal Width (cm)**\n",
    "\n",
    "The dataset does not contain any missing values and has a balanced class distribution, with 33.3% of instances belonging to each class.\n",
    "\n",
    "The summary statistics for the features include the minimum, maximum, mean, standard deviation (SD), and class correlation for each attribute. Notably, petal length and petal width have high correlations with the class, making them important features for classification.\n",
    "\n",
    "The Iris dataset was originally created by Sir R.A. Fisher and has been widely used in pattern recognition literature for classification and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'],columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset Keys\n",
    "\n",
    "The Iris dataset is stored in a dictionary with the following keys:\n",
    "\n",
    "- **data**: The feature data of the dataset, containing the numerical attributes (sepal length, sepal width, petal length, and petal width).\n",
    "- **target**: The target variable, containing the class labels for each sample (Iris-Setosa, Iris-Versicolour, or Iris-Virginica).\n",
    "- **frame**: A DataFrame with the feature data and the target labels.\n",
    "- **target_names**: The names of the classes (Iris-Setosa, Iris-Versicolour, Iris-Virginica).\n",
    "- **DESCR**: A detailed description of the dataset.\n",
    "- **feature_names**: The names of the features (sepal length, sepal width, petal length, and petal width).\n",
    "- **filename**: The location where the dataset is stored.\n",
    "- **data_module**: The module from which the dataset was loaded.\n",
    "\n",
    "These keys provide access to different parts of the Iris dataset, which can be used for further analysis and model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Class Names\n",
    "\n",
    "The target class names in the Iris dataset are:\n",
    "\n",
    "- **Setosa**\n",
    "- **Versicolor**\n",
    "- **Virginica**\n",
    "\n",
    "These represent the three species of iris plants in the dataset. Each instance in the dataset is classified into one of these three classes, and these names correspond to the labels in the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (X_train): (120, 4)\n",
      "Testing Features (X_test): (30, 4)\n",
      "Training Target (y_train): (120,)\n",
      "Testing Target (y_test): (30,)\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the feature columns (data) and the target variable (target)\n",
    "X = df\n",
    "y = data.target\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting sets to confirm the split\n",
    "print(f\"Training Features (X_train): {X_train.shape}\")\n",
    "print(f\"Testing Features (X_test): {X_test.shape}\")\n",
    "print(f\"Training Target (y_train): {y_train.shape}\")\n",
    "print(f\"Testing Target (y_test): {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split for Iris Dataset\n",
    "\n",
    "The Iris dataset has been successfully split into training and testing sets:\n",
    "\n",
    "- **Training Features (X_train)**: The training set contains 120 samples with 4 features each (sepal length, sepal width, petal length, and petal width).\n",
    "  \n",
    "- **Testing Features (X_test)**: The testing set contains 30 samples with 4 features each.\n",
    "\n",
    "- **Training Target (y_train)**: The training target set contains 120 values, corresponding to the classes of the iris plants (Setosa, Versicolor, or Virginica).\n",
    "\n",
    "- **Testing Target (y_test)**: The testing target set contains 30 values, corresponding to the classes of the iris plants for the testing data.\n",
    "\n",
    "The data has been split such that 80% is used for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Predictions: [0 0 1 0 0 2 1 0 0 0 2 1 1 0 0 1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1\n",
      " 2 0 1 2 0 2 2 1 1 2 1 0 1 2 0 0 1 2 0 2 0 0 2 1 2 2 2 2 1 0 0 2 2 0 0 0 1\n",
      " 2 0 2 2 0 1 1 2 1 2 0 2 1 2 1 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1\n",
      " 1 2 2 0 1 2 0 1 2]\n",
      "Testing Set Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on both the training and testing sets\n",
    "y_train_pred = log_reg_model.predict(X_train)\n",
    "y_test_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Display the predictions for both sets\n",
    "print(f\"Training Set Predictions: {y_train_pred}\")\n",
    "print(f\"Testing Set Predictions: {y_test_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Training and Testing Sets (Logistic Regression)\n",
    "\n",
    "The Logistic Regression model has been trained and predictions have been generated for both the training and testing sets:\n",
    "\n",
    "- **Training Set Predictions**: These are the predicted class labels for the training set. Each predicted value corresponds to one of the three classes: \n",
    "    - 0: Iris-Setosa\n",
    "    - 1: Iris-Versicolor\n",
    "    - 2: Iris-Virginica\n",
    "\n",
    "  The predictions show that the model has assigned class labels to the 120 samples in the training set.\n",
    "\n",
    "- **Testing Set Predictions**: These are the predicted class labels for the testing set, with 30 samples. Similarly, each prediction corresponds to one of the three classes.\n",
    "\n",
    "The model has made class predictions for both the training and testing data, and these can be further evaluated using metrics such as accuracy, confusion matrix, or classification report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Training Set: 0.975\n",
      "Accuracy for Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy score for both training and testing sets\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the accuracy scores\n",
    "print(f\"Accuracy for Training Set: {accuracy_train}\")\n",
    "print(f\"Accuracy for Testing Set: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for Training and Testing Sets\n",
    "\n",
    "The accuracy scores for the Logistic Regression model have been calculated for both the training and testing sets:\n",
    "\n",
    "- **Accuracy for Training Set**: The model achieved an accuracy of 97.5% on the training set, meaning it correctly predicted the class labels for 97.5% of the samples in the training data.\n",
    "\n",
    "- **Accuracy for Testing Set**: The model achieved perfect accuracy of 100% on the testing set, meaning it correctly predicted the class labels for all 30 samples in the testing data.\n",
    "\n",
    "These high accuracy scores indicate that the model is performing very well on both the training and testing sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy for Training Set: 0.975609756097561\n",
      "Balanced Accuracy for Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calculate balanced accuracy score for both training and testing sets\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the balanced accuracy scores\n",
    "print(f\"Balanced Accuracy for Training Set: {balanced_accuracy_train}\")\n",
    "print(f\"Balanced Accuracy for Testing Set: {balanced_accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy for Training and Testing Sets\n",
    "\n",
    "The balanced accuracy scores for the Logistic Regression model have been calculated for both the training and testing sets:\n",
    "\n",
    "- **Balanced Accuracy for Training Set**: The balanced accuracy for the training set is 97.56%, which indicates that the model performs well across all classes in the training data, with each class receiving similar treatment in terms of prediction accuracy.\n",
    "\n",
    "- **Balanced Accuracy for Testing Set**: The balanced accuracy for the testing set is 100%, which indicates that the model performed perfectly on the testing data, with an equal and excellent prediction across all classes.\n",
    "\n",
    "The balanced accuracy metric confirms the model's ability to handle class balance effectively, and the results indicate strong performance on both sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Training Set: 0.9767857142857144\n",
      "Precision for Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision score for both training and testing sets\n",
    "precision_train = precision_score(y_train, y_train_pred, average='weighted')\n",
    "precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print the precision scores\n",
    "print(f\"Precision for Training Set: {precision_train}\")\n",
    "print(f\"Precision for Testing Set: {precision_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision for Training and Testing Sets\n",
    "\n",
    "The precision scores for the Logistic Regression model have been calculated for both the training and testing sets:\n",
    "\n",
    "- **Precision for Training Set**: The precision for the training set is 97.68%, indicating that when the model predicts a positive class, it is correct 97.68% of the time. This reflects the model's ability to avoid false positives.\n",
    "\n",
    "- **Precision for Testing Set**: The precision for the testing set is 100%, meaning that all of the positive class predictions made by the model on the testing set were correct.\n",
    "\n",
    "These precision scores demonstrate the model's effectiveness in correctly identifying positive class instances while avoiding false positives, with perfect precision on the testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for Training Set: 0.975\n",
      "Recall for Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall score for both training and testing sets\n",
    "recall_train = recall_score(y_train, y_train_pred, average='weighted')\n",
    "recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print the recall scores\n",
    "print(f\"Recall for Training Set: {recall_train}\")\n",
    "print(f\"Recall for Testing Set: {recall_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall for Training and Testing Sets\n",
    "\n",
    "The recall scores for the Logistic Regression model have been calculated for both the training and testing sets:\n",
    "\n",
    "- **Recall for Training Set**: The recall for the training set is 97.5%, indicating that the model correctly identifies 97.5% of the actual positive instances in the training data.\n",
    "\n",
    "- **Recall for Testing Set**: The recall for the testing set is 100%, meaning that the model correctly identified all of the actual positive instances in the testing data.\n",
    "\n",
    "These recall scores demonstrate that the model performs well in identifying positive class instances, with perfect recall on the testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training Set: 0.9749882794186592\n",
      "F1 Score for Testing Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for both training and testing sets\n",
    "f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print the F1 scores\n",
    "print(f\"F1 Score for Training Set: {f1_train}\")\n",
    "print(f\"F1 Score for Testing Set: {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score for Training and Testing Sets\n",
    "\n",
    "The F1 scores for the Logistic Regression model have been calculated for both the training and testing sets:\n",
    "\n",
    "- **F1 Score for Training Set**: The F1 score for the training set is 0.975, indicating a good balance between precision and recall on the training data.\n",
    "\n",
    "- **F1 Score for Testing Set**: The F1 score for the testing set is 1.0, representing perfect precision and recall on the testing data, with no false positives or false negatives.\n",
    "\n",
    "The F1 scores suggest that the model performs well, with a high degree of accuracy in both training and testing sets, especially in the testing set where the F1 score is perfect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate confusion matrix for both training and testing sets\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Plot the confusion matrix for the training set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.title(\"Confusion Matrix for Training Set\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix for the testing set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.title(\"Confusion Matrix for Testing Set\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices for Training and Testing Sets\n",
    "\n",
    "The confusion matrices for both the training and testing sets are shown below:\n",
    "\n",
    "- **Confusion Matrix for Training Set**: \n",
    "  - The model made 40 correct predictions for Iris-Setosa (True Positive).\n",
    "  - The model made 38 correct predictions for Iris-Versicolor and 3 misclassifications, where it predicted Iris-Versicolor as Iris-Virginica.\n",
    "  - The model made 39 correct predictions for Iris-Virginica with no misclassifications.\n",
    "\n",
    "- **Confusion Matrix for Testing Set**:\n",
    "  - The model made 10 correct predictions for Iris-Setosa.\n",
    "  - The model made 9 correct predictions for Iris-Versicolor and no misclassifications.\n",
    "  - The model made 11 correct predictions for Iris-Virginica, with no misclassifications.\n",
    "\n",
    "Overall, the confusion matrices show that the model is performing very well on both the training and testing sets, with only a few misclassifications in the training set for Iris-Versicolor. There are no misclassifications in the testing set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                MSE (Train)  MSE (Test)  R2 (Train)  \\\n",
      "Linear Regression                  0.049093    0.037114    0.925420   \n",
      "Random Forest Regressor            0.006333    0.001400    0.990379   \n",
      "Support Vector Regressor (SVR)     0.034385    0.040240    0.947765   \n",
      "K-Nearest Neighbors Regressor      0.024000    0.008000    0.963540   \n",
      "\n",
      "                                R2 (Test)  MAE (Train)  MAE (Test)  \n",
      "Linear Regression                0.946896     0.171397    0.146377  \n",
      "Random Forest Regressor          0.997997     0.026333    0.012000  \n",
      "Support Vector Regressor (SVR)   0.942423     0.127949    0.158924  \n",
      "K-Nearest Neighbors Regressor    0.988553     0.046667    0.026667  \n",
      "Results saved to 'housing_model_comparison_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Have fun here !\n",
    "\n",
    "# Import necessary models for regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize models for regression\n",
    "models_regression = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Support Vector Regressor (SVR)': SVR(),\n",
    "    'K-Nearest Neighbors Regressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results_regression = {}\n",
    "\n",
    "# Train and evaluate each model on the Housing dataset\n",
    "for model_name, model in models_regression.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results_regression[model_name] = {\n",
    "        'MSE (Train)': mse_train,\n",
    "        'MSE (Test)': mse_test,\n",
    "        'R2 (Train)': r2_train,\n",
    "        'R2 (Test)': r2_test,\n",
    "        'MAE (Train)': mae_train,\n",
    "        'MAE (Test)': mae_test\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_regression_df = pd.DataFrame(results_regression).T\n",
    "\n",
    "# Display the results\n",
    "print(results_regression_df)\n",
    "\n",
    "# Optional: Save results to a CSV file\n",
    "results_regression_df.to_csv(\"housing_model_comparison_results.csv\", index=True)\n",
    "print(\"Results saved to 'housing_model_comparison_results.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Results for Housing Dataset\n",
    "\n",
    "The performance of different regression models on the Housing dataset has been evaluated using several metrics: MSE, RÂ², and MAE for both the training and testing sets. Below are the results:\n",
    "\n",
    "- **Linear Regression**:\n",
    "  - MSE (Train): 0.0491, MSE (Test): 0.0371\n",
    "  - RÂ² (Train): 0.9254, RÂ² (Test): 0.9469\n",
    "  - MAE (Train): 0.1714, MAE (Test): 0.1464\n",
    "\n",
    "- **Random Forest Regressor**:\n",
    "  - MSE (Train): 0.0063, MSE (Test): 0.0014\n",
    "  - RÂ² (Train): 0.9904, RÂ² (Test): 0.9980\n",
    "  - MAE (Train): 0.0263, MAE (Test): 0.0120\n",
    "\n",
    "- **Support Vector Regressor (SVR)**:\n",
    "  - MSE (Train): 0.0344, MSE (Test): 0.0402\n",
    "  - RÂ² (Train): 0.9478, RÂ² (Test): 0.9424\n",
    "  - MAE (Train): 0.1280, MAE (Test): 0.1589\n",
    "\n",
    "- **K-Nearest Neighbors Regressor**:\n",
    "  - MSE (Train): 0.0240, MSE (Test): 0.0080\n",
    "  - RÂ² (Train): 0.9635, RÂ² (Test): 0.9886\n",
    "  - MAE (Train): 0.0467, MAE (Test): 0.0267\n",
    "\n",
    "**Key Observations**:\n",
    "- **Random Forest Regressor** performed the best on both the training and testing sets, with the lowest MSE and highest RÂ² scores. It achieved perfect results on the testing set.\n",
    "- **Linear Regression** performed well with a high RÂ² on the training set, but the model is slightly less effective on the test set compared to other models.\n",
    "- **Support Vector Regressor (SVR)** showed good performance but had a slightly higher error on the test set.\n",
    "- **K-Nearest Neighbors** performed well, with good generalization to the test set, but slightly higher MAE compared to Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Accuracy (Train)  Accuracy (Test)  \\\n",
      "Logistic Regression                     0.975000              1.0   \n",
      "SVM                                     0.975000              1.0   \n",
      "Random Forest Classifier                1.000000              1.0   \n",
      "K-Nearest Neighbors Classifier          0.966667              1.0   \n",
      "\n",
      "                                Balanced Accuracy (Train)  \\\n",
      "Logistic Regression                              0.975610   \n",
      "SVM                                              0.975193   \n",
      "Random Forest Classifier                         1.000000   \n",
      "K-Nearest Neighbors Classifier                   0.967063   \n",
      "\n",
      "                                Balanced Accuracy (Test)  F1 Score (Train)  \\\n",
      "Logistic Regression                                  1.0          0.974988   \n",
      "SVM                                                  1.0          0.975004   \n",
      "Random Forest Classifier                             1.0          1.000000   \n",
      "K-Nearest Neighbors Classifier                       1.0          0.966667   \n",
      "\n",
      "                                F1 Score (Test)  Precision (Train)  \\\n",
      "Logistic Regression                         1.0           0.976786   \n",
      "SVM                                         1.0           0.975208   \n",
      "Random Forest Classifier                    1.0           1.000000   \n",
      "K-Nearest Neighbors Classifier              1.0           0.967459   \n",
      "\n",
      "                                Precision (Test)  Recall (Train)  \\\n",
      "Logistic Regression                          1.0        0.975000   \n",
      "SVM                                          1.0        0.975000   \n",
      "Random Forest Classifier                     1.0        1.000000   \n",
      "K-Nearest Neighbors Classifier               1.0        0.966667   \n",
      "\n",
      "                                Recall (Test)  \n",
      "Logistic Regression                       1.0  \n",
      "SVM                                       1.0  \n",
      "Random Forest Classifier                  1.0  \n",
      "K-Nearest Neighbors Classifier            1.0  \n",
      "Results saved to 'iris_model_comparison_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary models for classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize models for classification\n",
    "models_classification = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'K-Nearest Neighbors Classifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results_classification = {}\n",
    "\n",
    "# Train and evaluate each model on the Iris dataset\n",
    "for model_name, model in models_classification.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "    balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    precision_train = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    precision_test = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall_train = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    recall_test = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results_classification[model_name] = {\n",
    "        'Accuracy (Train)': accuracy_train,\n",
    "        'Accuracy (Test)': accuracy_test,\n",
    "        'Balanced Accuracy (Train)': balanced_accuracy_train,\n",
    "        'Balanced Accuracy (Test)': balanced_accuracy_test,\n",
    "        'F1 Score (Train)': f1_train,\n",
    "        'F1 Score (Test)': f1_test,\n",
    "        'Precision (Train)': precision_train,\n",
    "        'Precision (Test)': precision_test,\n",
    "        'Recall (Train)': recall_train,\n",
    "        'Recall (Test)': recall_test\n",
    "    }\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_classification_df = pd.DataFrame(results_classification).T\n",
    "\n",
    "# Display the results\n",
    "print(results_classification_df)\n",
    "\n",
    "# Optional: Save results to a CSV file\n",
    "results_classification_df.to_csv(\"iris_model_comparison_results.csv\", index=True)\n",
    "print(\"Results saved to 'iris_model_comparison_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Results for Iris Dataset\n",
    "\n",
    "The performance of different classification models on the Iris dataset has been evaluated using several metrics: Accuracy, Balanced Accuracy, F1 Score, Precision, and Recall for both the training and testing sets. Below are the results:\n",
    "\n",
    "- **Logistic Regression**:\n",
    "  - Accuracy (Train): 97.5%, Accuracy (Test): 100%\n",
    "  - Balanced Accuracy (Train): 97.56%, Balanced Accuracy (Test): 100%\n",
    "  - F1 Score (Train): 97.5%, F1 Score (Test): 100%\n",
    "  - Precision (Train): 97.68%, Precision (Test): 100%\n",
    "  - Recall (Train): 97.5%, Recall (Test): 100%\n",
    "\n",
    "- **SVM**:\n",
    "  - Accuracy (Train): 97.5%, Accuracy (Test): 100%\n",
    "  - Balanced Accuracy (Train): 97.52%, Balanced Accuracy (Test): 100%\n",
    "  - F1 Score (Train): 97.5%, F1 Score (Test): 100%\n",
    "  - Precision (Train): 97.52%, Precision (Test): 100%\n",
    "  - Recall (Train): 97.5%, Recall (Test): 100%\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "  - Accuracy (Train): 100%, Accuracy (Test): 100%\n",
    "  - Balanced Accuracy (Train): 100%, Balanced Accuracy (Test): 100%\n",
    "  - F1 Score (Train): 100%, F1 Score (Test): 100%\n",
    "  - Precision (Train): 100%, Precision (Test): 100%\n",
    "  - Recall (Train): 100%, Recall (Test): 100%\n",
    "\n",
    "- **K-Nearest Neighbors Classifier**:\n",
    "  - Accuracy (Train): 96.67%, Accuracy (Test): 100%\n",
    "  - Balanced Accuracy (Train): 96.71%, Balanced Accuracy (Test): 100%\n",
    "  - F1 Score (Train): 96.67%, F1 Score (Test): 100%\n",
    "  - Precision (Train): 96.75%, Precision (Test): 100%\n",
    "  - Recall (Train): 96.67%, Recall (Test): 100%\n",
    "\n",
    "**Key Observations**:\n",
    "- **Random Forest Classifier** performed the best on both the training and testing sets, achieving perfect scores across all metrics.\n",
    "- **Logistic Regression** and **SVM** performed similarly, with high accuracy and balanced accuracy, but **Random Forest** outperformed them with perfect results.\n",
    "- **K-Nearest Neighbors** performed well with a slightly lower training accuracy compared to the other models but still achieved perfect accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
